{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnza0H4V3MSP"
   },
   "outputs": [],
   "source": [
    "##Lectura de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#funciones para preprocesado de datos\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "##Funciones para el analisis y guardado del modelo\n",
    "import pandas_profiling\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leemos y procesamos las datos para unir la informacion estatica con la info transaccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160192,
     "status": "ok",
     "timestamp": 1575047274661,
     "user": {
      "displayName": "Juan Manuel Ciro Torres",
      "photoUrl": "",
      "userId": "12480051337774408405"
     },
     "user_tz": 300
    },
    "id": "j97lP9TM3MS-",
    "outputId": "9a03fb79-d35c-4b1c-a52f-b019eab045ee"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/DT19_Datos_Var_Rpta_train.csv')\n",
    "df_detail = pd.read_csv('data/DT19_Datos_transaccionales_train.csv')\n",
    "df_id = pd.read_csv('data/DT19_IDs_predict.csv')\n",
    "df_trans_predict = pd.read_csv('data/DT19_Datos_transaccionales_predict.csv')\n",
    "df['train'] = 1\n",
    "df_id['train'] = 0\n",
    "print(df_detail.shape, df_trans_predict.shape)\n",
    "print(df_id.shape, df.shape)\n",
    "df = pd.concat([df, df_id])\n",
    "df_detail = pd.concat([df_detail, df_trans_predict])\n",
    "df_meta = pd.read_csv('data/DT19_maestro_cdgtrn_cdgrpta.csv')\n",
    "df_meta.fillna(0, inplace=True)\n",
    "df_detail['cdgrpta'] = df_detail['cdgrpta'].astype(float)\n",
    "df_detail['cdgtrn'] = df_detail['cdgtrn'].astype(float)\n",
    "df_detail['cdgrpta'] = df_detail['cdgrpta'].astype(str)\n",
    "df_detail['cdgtrn'] = df_detail['cdgtrn'].astype(str)\n",
    "print (df_detail.shape)\n",
    "df_detail = pd.merge(df, df_detail, on=['id'])\n",
    "print (df_detail.shape)\n",
    "df_detail = pd.merge(df_detail, df_meta, on=['canal','disposit','cdgtrn','cdgrpta'])\n",
    "df_detail['fecha_trxn'] =  pd.to_datetime(df_detail['fecha_trxn'])\n",
    "df_detail['year'] = df_detail['fecha_trxn'].dt.year\n",
    "df_detail['month'] = df_detail['fecha_trxn'].dt.month\n",
    "df_detail['day'] = df_detail['fecha_trxn'].dt.day\n",
    "df_detail['quarter'] = df_detail['fecha_trxn'].dt.quarter\n",
    "df_detail['dayofweek'] = df_detail['fecha_trxn'].dt.dayofweek\n",
    "df_detail['hour'] = df_detail['fecha_trxn'].dt.hour\n",
    "df_detail['second'] = df_detail['fecha_trxn'].dt.second\n",
    "df_detail['weekofyear'] = df_detail['fecha_trxn'].dt.strftime(\"%V\")\n",
    "df_detail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos los dataframe finales para no tener que repetir este proceso en futuras cargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle('df_detail.plk')\n",
    "pd.to_pickle('df_final.plk')\n",
    "pd.to_pickle('df.plk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leemos los dataframes preprocesados  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109337, 5) (109337, 1210)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_analisis</th>\n",
       "      <th>id</th>\n",
       "      <th>segmento</th>\n",
       "      <th>train</th>\n",
       "      <th>var_rpta</th>\n",
       "      <th>canal_CANAL_5_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_2_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_6_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_8_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_3_cantidad_sesiones</th>\n",
       "      <th>...</th>\n",
       "      <th>day_27_cantidad_sesiones</th>\n",
       "      <th>day_28_cantidad_sesiones</th>\n",
       "      <th>day_29_cantidad_sesiones</th>\n",
       "      <th>day_30_cantidad_sesiones</th>\n",
       "      <th>day_31_cantidad_sesiones</th>\n",
       "      <th>day_4_cantidad_sesiones</th>\n",
       "      <th>day_11_cantidad_sesiones</th>\n",
       "      <th>day_15_cantidad_sesiones</th>\n",
       "      <th>day_17_cantidad_sesiones</th>\n",
       "      <th>day_23_cantidad_sesiones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>201803</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>201604</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>201608</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>201706</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>201703</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  f_analisis  id  segmento  train  var_rpta  canal_CANAL_5_cantidad_sesiones  \\\n",
       "0     201803   1         4      1       0.0                             69.0   \n",
       "1     201604   2         0      1       0.0                              2.0   \n",
       "2     201608   3         5      1       0.0                              0.0   \n",
       "3     201706   4         4      1       0.0                            618.0   \n",
       "4     201703   5         4      1       0.0                             70.0   \n",
       "\n",
       "   canal_CANAL_2_cantidad_sesiones  canal_CANAL_6_cantidad_sesiones  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                              3.0                              0.0   \n",
       "3                              0.0                              1.0   \n",
       "4                              1.0                             46.0   \n",
       "\n",
       "   canal_CANAL_8_cantidad_sesiones  canal_CANAL_3_cantidad_sesiones  ...  \\\n",
       "0                              0.0                              0.0  ...   \n",
       "1                              0.0                              0.0  ...   \n",
       "2                              0.0                              0.0  ...   \n",
       "3                              0.0                              0.0  ...   \n",
       "4                              2.0                              0.0  ...   \n",
       "\n",
       "   day_27_cantidad_sesiones  day_28_cantidad_sesiones  \\\n",
       "0                       2.0                       2.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       1.0                       0.0   \n",
       "3                      12.0                      23.0   \n",
       "4                       3.0                       4.0   \n",
       "\n",
       "   day_29_cantidad_sesiones  day_30_cantidad_sesiones  \\\n",
       "0                       2.0                       6.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                      24.0                      16.0   \n",
       "4                       1.0                       3.0   \n",
       "\n",
       "   day_31_cantidad_sesiones  day_4_cantidad_sesiones  \\\n",
       "0                       2.0                      0.0   \n",
       "1                       0.0                      0.0   \n",
       "2                       0.0                      1.0   \n",
       "3                      14.0                     20.0   \n",
       "4                       2.0                      4.0   \n",
       "\n",
       "   day_11_cantidad_sesiones  day_15_cantidad_sesiones  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                      15.0                      20.0   \n",
       "4                       5.0                      12.0   \n",
       "\n",
       "   day_17_cantidad_sesiones  day_23_cantidad_sesiones  \n",
       "0                       0.0                       0.0  \n",
       "1                       0.0                       0.0  \n",
       "2                       0.0                       0.0  \n",
       "3                      15.0                      14.0  \n",
       "4                       3.0                       5.0  \n",
       "\n",
       "[5 rows x 1210 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detail = pd.read_pickle('df_detail.plk')\n",
    "df_final = pd.read_pickle('df_final.plk')\n",
    "df = pd.read_pickle('df.plk')\n",
    "print ( df.shape, df_final.shape)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_eda = df[df['train'] == 1]\n",
    "df_eda['f_analisis'] = df_eda['f_analisis'].astype(str)\n",
    "df_eda['year'] = [ value[:4] for value in df_eda['f_analisis']]\n",
    "df_eda['year'] = df_eda['year'].astype(int)\n",
    "df_eda['month'] = [ value[4:] for value in df_eda['f_analisis'] ]\n",
    "df_eda['month'] = df_eda['month'].astype(int)\n",
    "df_eda.fillna(0, inplace=True)\n",
    "profile = df_eda.profile_report(title='BancolombiaEDA')\n",
    "profile.to_file(output_file=\"bancolombiaEDA.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos las caracteristicas (feature engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupamiento de sesiones unicas por cada una de las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUgxxjIF9nQ9"
   },
   "outputs": [],
   "source": [
    "columns = ['canal', 'disposit','grupo_descrp_trxn',\n",
    "           'descrip_trxn','clasif_trxn','clasif_cod_rpta','producto_asociado',\n",
    "          'descripcion_grupo', 'descrip_cod_rpta','grupo_modifcado','culpa_banco']\n",
    "\n",
    "df_final = df.copy()\n",
    "##Cantidad de sesiones unicas por canal, dispositivo\n",
    "for column in columns:\n",
    "    print (column)\n",
    "    df_final_group = df_detail.groupby(['id',column], as_index=False).agg({'sesion':'nunique'})\n",
    "    for value in df_final_group[column].unique():\n",
    "        data = df_final_group[df_final_group[column] == value]\n",
    "        data.drop([column], axis=1, inplace=True)\n",
    "        df_final = pd.merge(df_final, data, on=['id'], how='left')\n",
    "        df_final.fillna(0, inplace=True)\n",
    "        df_final.rename(columns={'sesion':str(column) + '_' + str(value) + '_cantidad_sesiones' }, inplace=True)\n",
    "\n",
    "        \n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de factores estadísticos sum, mean, max, min y std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Valor sum, max, min,mean y std del valor de transaccion\n",
    "sum_vlr = df_detail.groupby(['id'], as_index=False).sum()[['id','vlrtran', 'sesion', 'year', 'month',\n",
    "       'day', 'hour', 'minute', 'second', 'quarter', 'dayofweek']]\n",
    "df_final = pd.merge(df_final, sum_vlr, on=['id'], how='left')\n",
    "df_final.rename(columns={'vlrtran':'vlrtran_sum',\n",
    "                        'sesion':'sesion_sum',\n",
    "                        'year':'year_sum',\n",
    "                        'month':'month_sum',\n",
    "                        'day':'day_sum',\n",
    "                        'hour':'hour_sum',\n",
    "                        'minute':'minute_sum',\n",
    "                        'second':'second_sum',\n",
    "                        'quarter':'quarter_sum',\n",
    "                        'dayofweek':'dayofweek_sum'}, inplace=True)\n",
    "print(df_final.shape)\n",
    "min_vlr = df_detail.groupby(['id'], as_index=False).min()[['id','vlrtran', 'sesion', 'year', 'month',\n",
    "       'day', 'hour', 'minute', 'second', 'quarter', 'dayofweek']]\n",
    "df_final = pd.merge(df_final, min_vlr, on=['id'], how='left')\n",
    "df_final.rename(columns={'vlrtran':'vlrtran_min',\n",
    "                        'sesion':'sesion_min',\n",
    "                        'year':'year_min',\n",
    "                        'month':'month_min',\n",
    "                        'day':'day_min',\n",
    "                        'hour':'hour_min',\n",
    "                        'minute':'minute_min',\n",
    "                        'second':'second_min',\n",
    "                        'quarter':'quarter_min',\n",
    "                        'dayofweek':'dayofweek_min'}, inplace=True)\n",
    "print(df_final.shape)\n",
    "\n",
    "max_vlr = df_detail.groupby(['id'], as_index=False).max()[['id','vlrtran', 'sesion', 'year', 'month',\n",
    "       'day', 'hour', 'minute', 'second', 'quarter', 'dayofweek']]\n",
    "df_final = pd.merge(df_final, max_vlr, on=['id'], how='left')\n",
    "df_final.rename(columns={'vlrtran':'vlrtran_max',\n",
    "                        'sesion':'sesion_max',\n",
    "                        'year':'year_max',\n",
    "                        'month':'month_max',\n",
    "                        'day':'day_max',\n",
    "                        'hour':'hour_max',\n",
    "                        'minute':'minute_max',\n",
    "                        'second':'second_max',\n",
    "                        'quarter':'quarter_max',\n",
    "                        'dayofweek':'dayofweek_max'}, inplace=True)\n",
    "print(df_final.shape)\n",
    "\n",
    "\n",
    "mean_vlr = df_detail.groupby(['id'], as_index=False).mean()[['id','vlrtran', 'sesion', 'year', 'month',\n",
    "       'day', 'hour', 'minute', 'second', 'quarter', 'dayofweek']]\n",
    "df_final = pd.merge(df_final, mean_vlr, on=['id'], how='left')\n",
    "df_final.rename(columns={'vlrtran':'vlrtran_mean',\n",
    "                        'sesion':'sesion_mean',\n",
    "                        'year':'year_mean',\n",
    "                        'month':'month_mean',\n",
    "                        'day':'day_mean',\n",
    "                        'hour':'hour_mean',\n",
    "                        'minute':'minute_mean',\n",
    "                        'second':'second_mean',\n",
    "                        'quarter':'quarter_mean',\n",
    "                        'dayofweek':'dayofweek_mean'}, inplace=True)\n",
    "print(df_final.shape)\n",
    "\n",
    "std_vlr = df_detail.groupby(['id'], as_index=False).std()[['id','vlrtran', 'sesion', 'year', 'month',\n",
    "       'day', 'hour', 'minute', 'second', 'quarter', 'dayofweek']]\n",
    "df_final = pd.merge(df_final, std_vlr, on=['id'], how='left')\n",
    "df_final.rename(columns={'vlrtran':'vlrtran_std',\n",
    "                        'sesion':'sesion_std',\n",
    "                        'year':'year_std',\n",
    "                        'month':'month_std',\n",
    "                        'day':'day_std',\n",
    "                        'hour':'hour_std',\n",
    "                        'minute':'minute_std',\n",
    "                        'second':'second_std',\n",
    "                        'quarter':'quarter_std',\n",
    "                        'dayofweek':'dayofweek_std'}, inplace=True)\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One-hot encoding de los segmentos\n",
    "df_ = df.copy()\n",
    "df_['segmento'] = np.where(df_['segmento'] == 0, 6, df_['segmento'])\n",
    "dummy = pd.get_dummies(df_['segmento'], prefix='segmento',  drop_first=True)\n",
    "df_ = pd.concat([df[['id']], dummy], axis=1)\n",
    "df_final = pd.merge(df_final, df_, on=['id'], how='left')\n",
    "\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculado diferencia de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['f_analisis'] = df_final['f_analisis'].astype(str)\n",
    "df_final['year'] = [ value[:4] for value in df_final['f_analisis']]\n",
    "df_final['year'] = df_final['year'].astype(int)\n",
    "df_final['month'] = [ value[4:] for value in df_final['f_analisis'] ]\n",
    "df_final['month'] = df_final['month'].astype(int)\n",
    "df_final.fillna(0, inplace=True)\n",
    "\n",
    "##Diff fechas\n",
    "df_final['max_diff_year'] = df_final['year'] - df_final['year_max']\n",
    "df_final['min_diff_year'] = df_final['year'] - df_final['year_min']\n",
    "df_final['mean_diff_year'] = df_final['year'] - df_final['year_mean']\n",
    "df_final['max_diff_month'] = df_final['month'] - df_final['month_max']\n",
    "df_final['min_diff_month'] = df_final['month'] - df_final['month_min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porcentage de cada una de las posibles salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_detail = df_detail[\"var_rpta\"].value_counts(normalize=True)[1]\n",
    "no_fail_detail = df_detail[\"var_rpta\"].value_counts(normalize=True)[0]\n",
    "df_final['fail_detail'] = np.where(df_final['var_rpta'] == 1, fail_detail, fail_detail)\n",
    "df_final['no_fail_detail'] = np.where(df_final['var_rpta'] == 0, no_fail_detail, no_fail_detail)\n",
    "fail_detail = df[\"var_rpta\"].value_counts(normalize=True)[1]\n",
    "no_fail_detail = df[\"var_rpta\"].value_counts(normalize=True)[0]\n",
    "df_final['percentage_fail'] = np.where(df_final['var_rpta'] == 1, fail_detail, fail_detail)\n",
    "df_final['percentage_no_fail'] = np.where(df_final['var_rpta'] == 0, no_fail_detail, no_fail_detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MAZkGG_Utoy"
   },
   "source": [
    "### Importancia de las variables para clusterizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 707704,
     "status": "ok",
     "timestamp": 1575001620561,
     "user": {
      "displayName": "Juan Manuel Ciro Torres",
      "photoUrl": "",
      "userId": "12480051337774408405"
     },
     "user_tz": 300
    },
    "id": "11MZUHMgJDCu",
    "outputId": "78455d77-ad35-4c05-ef2e-f79b50103ad6"
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=2,\n",
    "    seed=27)\n",
    "model.fit(X_sc,y)\n",
    "score_train = model.score(X_train,y_train)\n",
    "score_test = model.score(X_test,y_test)\n",
    "print(\"Score train is: {} and Score test is {}\".format(score_train, score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 707647,
     "status": "ok",
     "timestamp": 1575001620562,
     "user": {
      "displayName": "Juan Manuel Ciro Torres",
      "photoUrl": "",
      "userId": "12480051337774408405"
     },
     "user_tz": 300
    },
    "id": "ob3zZHI-IjUb",
    "outputId": "0729f4e9-eb7c-4453-9f51-33ed87014bc3"
   },
   "outputs": [],
   "source": [
    "#Mirando las variables explicativas\n",
    "predictors = X.columns\n",
    "features = list(zip(predictors,model.feature_importances_))\n",
    "variables = pd.DataFrame(np.array(features).reshape(X.shape[1],2), columns = [\"Variable\",\"Peso\"])\n",
    "variables['Peso'] = variables['Peso'].astype(float)\n",
    "variables.sort_values([\"Peso\"], ascending=False, inplace=True)\n",
    "variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentacion propia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cluster con k-means\n",
    "variable = list(variables.head(80)['Variable'].values)\n",
    "variable.append('id')\n",
    "variable.append('var_rpta')\n",
    "df_final_t = df_final[variable].groupby('id').sum()\n",
    "X = df_final_t\n",
    "\n",
    "X.dropna(inplace=True)\n",
    "sc = MinMaxScaler()\n",
    "X_sc = sc.fit_transform(X)\n",
    "\n",
    "##Agrupamiento por KMeans con 5 clusters\n",
    "km = KMeans(n_clusters=250, random_state=5)\n",
    "km.fit(X_sc)\n",
    "labels = km.labels_\n",
    "mm = pd.DataFrame(km.fit_predict(X), columns=['labels'])\n",
    "silhouette = (X, mm['labels'])\n",
    "\n",
    "# Agregar cluster a los clientes\n",
    "df_final_cluster = df_final.copy()\n",
    "df_final[\"Medium Cluster\"] = km.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_ = list(variables[variables['Peso'] > 0.005]['Variable'].values)\n",
    "df_final = df_final[variables_]\n",
    "df_final = pd.concat([df[['id','var_rpta','train']].reset_index(drop=True), df_final], axis=1)\n",
    "print(df_final.shape)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_ = df_final[df_final['train'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7a35ifvz3MW4"
   },
   "outputs": [],
   "source": [
    "X = df_final_.drop([\"var_rpta\",'id','f_analisis','train'],axis=1)\n",
    "y = df_final_['var_rpta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segmento</th>\n",
       "      <th>canal_CANAL_5_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_2_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_6_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_8_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_3_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_1_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_4_cantidad_sesiones</th>\n",
       "      <th>canal_CANAL_7_cantidad_sesiones</th>\n",
       "      <th>disposit_DISPOSIT_4_cantidad_sesiones</th>\n",
       "      <th>...</th>\n",
       "      <th>day_27_cantidad_sesiones</th>\n",
       "      <th>day_28_cantidad_sesiones</th>\n",
       "      <th>day_29_cantidad_sesiones</th>\n",
       "      <th>day_30_cantidad_sesiones</th>\n",
       "      <th>day_31_cantidad_sesiones</th>\n",
       "      <th>day_4_cantidad_sesiones</th>\n",
       "      <th>day_11_cantidad_sesiones</th>\n",
       "      <th>day_15_cantidad_sesiones</th>\n",
       "      <th>day_17_cantidad_sesiones</th>\n",
       "      <th>day_23_cantidad_sesiones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   segmento  canal_CANAL_5_cantidad_sesiones  canal_CANAL_2_cantidad_sesiones  \\\n",
       "0         4                             69.0                              0.0   \n",
       "1         0                              2.0                              0.0   \n",
       "2         5                              0.0                              3.0   \n",
       "3         4                            618.0                              0.0   \n",
       "4         4                             70.0                              1.0   \n",
       "\n",
       "   canal_CANAL_6_cantidad_sesiones  canal_CANAL_8_cantidad_sesiones  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                              0.0                              0.0   \n",
       "3                              1.0                              0.0   \n",
       "4                             46.0                              2.0   \n",
       "\n",
       "   canal_CANAL_3_cantidad_sesiones  canal_CANAL_1_cantidad_sesiones  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              0.0   \n",
       "4                              0.0                              0.0   \n",
       "\n",
       "   canal_CANAL_4_cantidad_sesiones  canal_CANAL_7_cantidad_sesiones  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              0.0   \n",
       "4                              0.0                              0.0   \n",
       "\n",
       "   disposit_DISPOSIT_4_cantidad_sesiones  ...  day_27_cantidad_sesiones  \\\n",
       "0                                   69.0  ...                       2.0   \n",
       "1                                    2.0  ...                       0.0   \n",
       "2                                    1.0  ...                       1.0   \n",
       "3                                  618.0  ...                      12.0   \n",
       "4                                   70.0  ...                       3.0   \n",
       "\n",
       "   day_28_cantidad_sesiones  day_29_cantidad_sesiones  \\\n",
       "0                       2.0                       2.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                      23.0                      24.0   \n",
       "4                       4.0                       1.0   \n",
       "\n",
       "   day_30_cantidad_sesiones  day_31_cantidad_sesiones  \\\n",
       "0                       6.0                       2.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                      16.0                      14.0   \n",
       "4                       3.0                       2.0   \n",
       "\n",
       "   day_4_cantidad_sesiones  day_11_cantidad_sesiones  \\\n",
       "0                      0.0                       0.0   \n",
       "1                      0.0                       0.0   \n",
       "2                      1.0                       0.0   \n",
       "3                     20.0                      15.0   \n",
       "4                      4.0                       5.0   \n",
       "\n",
       "   day_15_cantidad_sesiones  day_17_cantidad_sesiones  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                      20.0                      15.0   \n",
       "4                      12.0                       3.0   \n",
       "\n",
       "   day_23_cantidad_sesiones  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                      14.0  \n",
       "4                       5.0  \n",
       "\n",
       "[5 rows x 1206 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00jp6ojf3MXE"
   },
   "outputs": [],
   "source": [
    "#Estandarizando los datos\n",
    "sc = StandardScaler()\n",
    "X_sc = sc.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sc, y,shuffle=False,test_size=0.2)\n",
    "models = [ RandomForestClassifier(), XGBClassifier(), AdaBoostClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kNNits-UzUU"
   },
   "source": [
    "## Evaluacion de los modelos posibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 168746,
     "status": "ok",
     "timestamp": 1575047929208,
     "user": {
      "displayName": "Juan Manuel Ciro Torres",
      "photoUrl": "",
      "userId": "12480051337774408405"
     },
     "user_tz": 300
    },
    "id": "D2aTGGn73MXQ",
    "outputId": "ad99282c-c47d-401b-ae9d-d402656eb8dd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_score = []\n",
    "for model in models:\n",
    "    model = model\n",
    "    score_model = cross_val_score(model,X_sc,y, cv=2,scoring='roc_auc')\n",
    "    score_final = score_model.mean()\n",
    "    cv_score.append(score_final)\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRVsMAn53MWn"
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = []\n",
    "model_e = XGBClassifier()\n",
    "score_model = cross_val_score(model_e,X_sc,y, cv=3,scoring='roc_auc')\n",
    "score_final = score_model.mean()\n",
    "cv_score.append(score_final)\n",
    "print(str(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'learning_rate': (0.01, 1.0),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3,10),\n",
    "    'subsample': (0.5, 1.0),  # Change for big datasets\n",
    "    'colsample': (0.5, 1.0),  # Change for datasets with lots of features\n",
    "    'gamma': (0, 5)}\n",
    " \n",
    "def xgboost_hyper_param(learning_rate,\n",
    "                        n_estimators,\n",
    "                        max_depth,\n",
    "                        subsample,\n",
    "                        colsample,\n",
    "                        gamma):\n",
    " \n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    " \n",
    "    clf = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        gamma=gamma)\n",
    "    return np.mean(cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc'))\n",
    " \n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgboost_hyper_param,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "optimizer.maximize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtEEHyM6U6-L"
   },
   "source": [
    "## Prediccion de los nuevos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_p = df_final[df_final['train'] == 0]\n",
    "X_p = df_final_p.drop([\"var_rpta\",'f_analisis','id','train'],axis=1)\n",
    "y_p = df_final_p['var_rpta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7438365740249023]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=4, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=2, seed=27,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score = []\n",
    "\n",
    "model_e = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=1,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=2,\n",
    "    seed=27)\n",
    "score_model = cross_val_score(model_e,X_sc,y, cv=3,scoring='roc_auc')\n",
    "score_final = score_model.mean()\n",
    "cv_score.append(score_final)\n",
    "print(str(cv_score))\n",
    "model_e.fit(X_sc, y, eval_metric=['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probabilidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>76537.0</td>\n",
       "      <td>0.037337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>76538.0</td>\n",
       "      <td>0.105088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>76539.0</td>\n",
       "      <td>0.241048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>76540.0</td>\n",
       "      <td>0.042008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>76541.0</td>\n",
       "      <td>0.025967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  probabilidad\n",
       "0  76537.0      0.037337\n",
       "1  76538.0      0.105088\n",
       "2  76539.0      0.241048\n",
       "3  76540.0      0.042008\n",
       "4  76541.0      0.025967"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estandarizando los datos\n",
    "sc = StandardScaler()\n",
    "#X_sc_p = sc.fit_transform(X_p)\n",
    "y_pred = model_e.predict_proba(X_sc)\n",
    "y_pred = pd.DataFrame(y_pred, columns=['Pago','probabilidad'])\n",
    "df_id = pd.read_csv('data/DT19_IDs_predict.csv')\n",
    "y_pred = pd.concat([df_id[['id']], y_pred[['probabilidad']]], axis=1)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "td00JKMaMpXp"
   },
   "outputs": [],
   "source": [
    "y_pred.to_csv('try1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado del modelo para futuras predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'modelo_final.pkl'\n",
    "pickle.dump(model_e, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "EDA 2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
